#

# Task: Analyze Bug (v2.1 with Metrics)

# Argument: $ARGUMENT$ (e.g., Sentry issue link, or bug description)

#

# This command is a "Diagnosis Director" that also logs metrics.

#

## Metrics Block (START)

# This entire command's execution MUST be tracked.

# 1. Set START_TIME = current_timestamp

# 2. Set TASK_ID = $ARGUMENT$ (or a hash of it)

# 3. Set BUG_ID = $ARGUMENT$ (or a hash of it)

# 4. Set TASK_STATUS = "fail" (Default state)

# 5. Set AGENTS_USED_LIST = []

# 6. Set HUMAN_FEEDBACK_LOOPS = 0

# 7. Set ERROR_MSG = "null"

# --- BEGIN TASK EXECUTION (TRY...) ---

## Phase 1: Session Setup

1.  Create a new session file for this diagnosis:
    - `touch .claude/sessions/context_session_bug_{BUG_ID}.md`
2.  Write the bug description from `$ARGUMENT$` into the file.

## Phase 2: Constitution & Analysis

1.  **Read the Constitution:** Read and parse `CLAUDE.md`.
2.  **Analyze Bug Report:** Read the `$ARGUMENT$` and look for keywords to identify the bug's nature (e.g., "performance", "security", "database", "UI crash").

## Phase 3: Specialist Team Selection (REFACTORED v2.2)

# This phase now includes the fallback to the @agent-librarian.

1.  **Analyze Keywords:** ... (e.g., "performance")
2.  **Scan for Specialists:** Scan `/.claude/agents` for specialists (e.g., `@performance-profiler`).
3.  **Assemble Diagnosis Team:**
    - `AGENT_LIST = []`
    - `REQUIRED_ROLE = "@performance-profiler"`
    - **(TRY): Check if agent exists:**
    - `if [ -f "/.claude/agents/$REQUIRED_ROLE.md" ]; then`
      - `AGENT_LIST.append($REQUIRED_ROLE)`
    - **(CATCH): Agent does not exist:**
    - `else`
      - print "Warning: Specialist `@performance-profiler` not found."
      - **Invoke Librarian:**
      - `claude @agent-librarian "scout: @performance-profiler"`
      - **(Stop or Wait):** (Aquí la metodología debe decidir: ¿detenemos la tarea actual y esperamos a que Daniel apruebe al nuevo agente, o continuamos con un equipo reducido?)
      - `print "Halting task. Please review the agent draft from @agent-librarian and re-run the analysis."`
      - `Set TASK_STATUS = "fail"`
      - `Set ERROR_MSG = "Missing specialist: @performance-profiler. @agent-librarian invoked."`
      - **(Run Metrics Block END and EXIT)**
    - `fi`

4.  **Store for Metrics:** Set `AGENTS_USED_LIST = $AGENT_LIST`
5.  **Announce the Team:** Announce the final selected diagnosis team.

## Phase 4: Initial Plan

- Write up a detailed _investigation plan_.
- Write this plan to the `context_session_bug_{BUG_ID}.md`.

## Phase 5: Advice (Run Diagnosis)

- Use the sub-agents (from `AGENTS_USED_LIST`) _in parallel_ to execute the investigation.
- **CRITICAL:** You MUST provide each agent with both the `CLAUDE.md` file and the `context_session_bug_{BUG_ID}.md` file.

## Phase 6: Synthesize Diagnosis

- Read all the analysis reports generated by the specialist agents.
- Consolidate all findings into a single, final report:
  - `touch .claude/doc/bug_{BUG_ID}/bug_diagnosis_report.md`
- The report should contain:
  - **Root Cause:** (e.g., "The bug is caused by an N+1 query...")
  - **Evidence:** (e.g., "See `performance_report.md`...")
  - **Recommendation:** (e.g., "The endpoint must be refactored...")

## Phase 7: Recommendation

- Present the final `bug_diagnosis_report.md` to me (Daniel).
- Ask for confirmation to proceed with a fix:
  - "Daniel, I have found the root cause. The diagnosis report is at `.../bug_diagnosis_report.md`."
  - "Shall I create a new issue for this fix and send it to the `dynamic-task-executor`?"
- (If Daniel asks for clarification, increment `HUMAN_FEEDBACK_LOOPS`)
- **Set TASK_STATUS = "success"** (Success means a diagnosis was _delivered_, not that the bug was fixed)

# --- END TASK EXECUTION (CATCH...) ---

## On Error

# (If any command from Phase 1-7 fails unexpectedly)

# 1. Set TASK_STATUS = "fail"

# 2. Set ERROR_MSG = "The specific error message from the failed command."

# --- (FINALLY...) ---

## Metrics Block (END)

# This block MUST run at the very end, regardless of success or failure.

# 1. Set END_TIME = current_timestamp

# 2. Calculate DURATION = END_TIME - START_TIME

# 3. Construct METRICS_JSON string:

# (Example: {"timestamp": "...", "task_id": "$TASK_ID", "command": "analyze-bug", "status": "$TASK_STATUS", "duration_ms": $DURATION, "agents_used": $AGENTS_USED_LIST, "human_feedback_loops": $HUMAN_FEEDBACK_LOOPS, "error_message": "$ERROR_MSG"})

# 4. Call @metrics-logger with the JSON payload, SILENTLY.

# (claude @metrics-logger "$METRICS_JSON" > /dev/null 2>&1)
